{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Strategy:\n",
    "    def __init__(self, data) -> None:\n",
    "        self.data = data\n",
    "        self.indicator = None\n",
    "\n",
    "data = [0,1,2,3,4,5]\n",
    "strat = Strategy(data)\n",
    "strat.__dict__.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len.__name__)\n",
    "print(len.__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt \n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "num_days = 730\n",
    "start=dt.date(2021, 1, 1)\n",
    "start = max(start, dt.date.today() - dt.timedelta(days=num_days-1))\n",
    "end = dt.date.today() \n",
    "print(start, end)\n",
    "data = yf.download(\"SPY\", interval=\"1h\", start=start, end=end, prepost=True)\n",
    "data = data.drop(['Adj Close'], axis=1)\n",
    "data.index = list(map(lambda x: dt.datetime.strptime(str(x).replace(\":\",\"\"), '%Y-%m-%d %H%M%S%z').replace(tzinfo=None), data.index))\n",
    "data = data.rename_axis(\"Datetime\").reset_index()\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestr = '2022-07-28 04:00:00'\n",
    "output = dt.datetime.strptime(timestr, '%Y-%m-%d %H:%M:%S')\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bokeh.colors\n",
    "\n",
    "# for c in dir(bokeh.colors.named):\n",
    "    # print(c, c.__class__)\n",
    "import bokeh.palettes\n",
    "print(bokeh.palettes.Dark2_8)\n",
    "\n",
    "# print(bokeh.colors.named.blue.__class__)\n",
    "# print(all_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top gainers aftermath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tradingview_screener import *\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "n_rows, df = (Query()\n",
    " .select('name', 'close', 'change', 'volume', 'relative_volume_10d_calc', 'market_cap_basic', 'float_shares_outstanding')\n",
    " .where(\n",
    "     Column('market_cap_basic') >= 1_000_000,\n",
    "     Column('relative_volume_10d_calc') > 1.2,\n",
    "     Column('change') > 5,\n",
    "     Column('volume') > 1E6,\n",
    "     Column('close') > 2,\n",
    "    )\n",
    " .order_by('change', ascending=False)\n",
    " .get_scanner_data())\n",
    "\n",
    "df.volume = df.volume * 1E-6\n",
    "df.market_cap_basic = df.market_cap_basic * 1E-6\n",
    "df.float_shares_outstanding = df.float_shares_outstanding * 1E-6\n",
    "df = df.rename(columns={\n",
    "    \"volume\": \"Volume (M)\", \n",
    "    \"market_cap_basic\": \"Market Cap (M)\",\n",
    "    \"change\": \"Change %\",\n",
    "    \"float_shares_outstanding\": \"Float (M)\"\n",
    "    })\n",
    "df = df[df.ticker.str.contains(\"NASDAQ:\") | df.ticker.str.contains(\"NYSE:\")]\n",
    "print(len(df))\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from pandas.tseries.offsets import BDay\n",
    "\n",
    "(dt.date(2024, 9, 1) - BDay(0)).date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from pandas.tseries.offsets import BDay\n",
    "\n",
    "# all_data = {dt.date.today() : df.ticker.to_list()}\n",
    "fake_date_range = [dt.date(2024, 9, i) for i in range(1, 30)]\n",
    "fake_data = {fake_date_range[i//2] : [str(j) for j in range(i, i+3)] for i in range(0, len(fake_date_range)*2,2)}\n",
    "print(fake_data)\n",
    "\n",
    "\n",
    "observation_time = 1 # days after making top gainer list\n",
    "for today_date in fake_date_range:\n",
    "    stocks_to_scan = set()\n",
    "    for time_delta in range(observation_time + 1):\n",
    "        # lookback_date = (today_date - BDay(time_delta)).date()\n",
    "        lookback_date = today_date - dt.timedelta(days=time_delta)\n",
    "        print(lookback_date)\n",
    "        if lookback_date in fake_data:\n",
    "            stocks_to_scan.update(fake_data[lookback_date])\n",
    "            print(\"updated:\", fake_data[lookback_date])\n",
    "    print(today_date, stocks_to_scan)\n",
    "    print()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Premarket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tradingview_screener import *\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "n_rows, df = (\n",
    "    Scanner.premarket_gainers\n",
    "    .select('name', 'close', 'volume', 'premarket_change', 'premarket_volume', 'relative_volume_10d_calc', 'market_cap_basic', 'float_shares_outstanding')\n",
    "    .where(\n",
    "     Column('market_cap_basic') >= 1_000_000,\n",
    "     Column('relative_volume_10d_calc') > 1.2,\n",
    "     Column('premarket_change') > 5,\n",
    "     Column('premarket_volume') > 1E6,\n",
    "     Column('close') > 1\n",
    "    )\n",
    "    .get_scanner_data())\n",
    "\n",
    "\n",
    "df.volume = df.volume * 1E-6\n",
    "df.market_cap_basic = df.market_cap_basic * 1E-6\n",
    "df.premarket_volume = df.premarket_volume * 1E-6\n",
    "df.float_shares_outstanding = df.float_shares_outstanding * 1E-6\n",
    "df = df.rename(columns={\n",
    "    \"volume\": \"Volume (M)\", \n",
    "    \"market_cap_basic\": \"Market Cap (M)\",\n",
    "    \"premarket_change\": \"Premarket %\",\n",
    "    \"premarket_change_abs\": \"Premarket $\",\n",
    "    \"premarket_volume\": \"Premarket Volume (M)\",\n",
    "    \"float_shares_outstanding\": \"Float (M)\"\n",
    "    })\n",
    "print(n_rows)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from download import *\n",
    "from visualize import *\n",
    "\n",
    "yf_df = download_from_yf(\"EBS\", \"1m\", dt.date(2024,8,28), dt.date(2024,8,30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', 2500)\n",
    "display(yf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from download import *\n",
    "from visualize import *\n",
    "\n",
    "polygon_df = download_from_polygon(\"EBS\", \"1m\", dt.date(2024,8,28), dt.date(2024,8,30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(polygon_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 3000)\n",
    "merged_df = yf_df.merge(polygon_df, how='left')\n",
    "display(merged_df)\n",
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_open = pd.to_datetime('09:30:00').time()\n",
    "market_close = pd.to_datetime('16:00:00').time()\n",
    "\n",
    "pre_post_data = polygon_df.loc[(polygon_df['Datetime'].dt.time <= market_open) | (polygon_df['Datetime'].dt.time >= market_close)]\n",
    "\n",
    "# TODO: Lookup not by exact value, but by the closest timestamp in yf_df after the query timestamp. \n",
    "for index, row in pre_post_data.iterrows():\n",
    "    yf_row = yf_df[yf_df['Datetime'] == row.Datetime]\n",
    "    assert len(yf_row) <= 1, \"Multiple of the same timestamps found.\"\n",
    "    yf_df.loc[yf_row.index, 'Volume'] = row.Volume\n",
    "    \n",
    "\n",
    "# pre_post_data[\"closest_timestamp\"] = pd.merge_asof(pre_post_data, yf_df, on='Datetime', direction='forward')['Datetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_market_calendars as mcal\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "market_schedule = mcal.get_calendar('NYSE').schedule(start_date='2024-01-01', end_date='2024-12-31')\n",
    "regular_business_days = market_schedule.loc[market_schedule['market_close'].dt.time >= pd.to_datetime('20:00:00').time()].index.to_list()\n",
    "\n",
    "regular_business_days = [i.to_pydatetime().date() for i in regular_business_days]\n",
    "print(regular_business_days)\n",
    "print((dt.datetime.now().date() + dt.timedelta(days=1)) in regular_business_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import datetime as dt\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "interval = 'Daily' # '5min'\n",
    "# url = f\"https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY&symbol=IBM&interval={interval}&outputsize=full&apikey=demo\"\n",
    "url = f\"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol=IBM&outputsize=full&apikey=demo\"\n",
    "r = requests.get(url)\n",
    "data = r.json()\n",
    "\n",
    "# data = yf.download('IBM', interval='1d', start=dt.datetime(1914,1,1), end=dt.datetime.today(), prepost=True, progress=False)\n",
    "# display(data)\n",
    "\n",
    "df = pd.DataFrame(columns=[\"Datetime\", 'Open', 'High', 'Low', 'Close', 'Volume'])\n",
    "for timestamp, ohlcv in data[f\"Time Series ({interval})\"].items():\n",
    "    df = pd.concat([pd.DataFrame([[dt.datetime.fromisoformat(timestamp),\n",
    "                     ohlcv['1. open'],\n",
    "                     ohlcv['2. high'],\n",
    "                     ohlcv['3. low'],\n",
    "                     ohlcv['4. close'],\n",
    "                     ohlcv['5. volume']]], columns=df.columns), df], ignore_index=True)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from download import * \n",
    "\n",
    "df = get_historical_data(\"EBS\", \"1m\", save_to_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 2500)\n",
    "display(df)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bisect import bisect_left\n",
    "import datetime as dt\n",
    "from download import * \n",
    "for query_date in [dt.date(2024, 1, 1) + dt.timedelta(days=i) for i in range(365)]:\n",
    "    result = most_recent_business_day(query_date)\n",
    "    print(query_date, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "\n",
    "file = 'C:\\\\Users\\\\georg\\\\GitHub\\\\money-tree\\\\test_run.html'\n",
    "\n",
    "gauth = GoogleAuth(settings_file='C:\\\\Users\\\\georg\\\\GitHub\\\\money-tree\\\\settings.yaml', http_timeout=30)\n",
    "drive = GoogleDrive(gauth)\n",
    "upload_file_list = [file] \n",
    "for upload_file in upload_file_list: \n",
    "    gfile = drive.CreateFile({'parents': [{'id': '1N_7YUWKB2ezW_d_fse719Xo_toFuqx0q'}]}) # Read file and set it as the content of this instance. \n",
    "    gfile.SetContentFile(upload_file) \n",
    "    gfile.Upload() # Upload the file.\n",
    "\n",
    "# list file\n",
    "file_list = drive.ListFile({'q': \"'{}' in parents and trashed=false\".format('1N_7YUWKB2ezW_d_fse719Xo_toFuqx0q')}).GetList() \n",
    "for file in file_list: \n",
    "    print('title: %s, id: %s' % (file['title'], file['id']))\n",
    "\n",
    "# # download file\n",
    "# for i, file in enumerate(sorted(file_list, key = lambda x: x['title']), start=1):\n",
    "#     print('Downloading {} file from GDrive ({}/{})'.format(file['title'], i, len(file_list))) \n",
    "#     file.GetContentFile(file['title'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
