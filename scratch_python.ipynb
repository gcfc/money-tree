{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Strategy:\n",
    "    def __init__(self, data) -> None:\n",
    "        self.data = data\n",
    "        self.indicator = None\n",
    "\n",
    "data = [0,1,2,3,4,5]\n",
    "strat = Strategy(data)\n",
    "strat.__dict__.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len.__name__)\n",
    "print(len.__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt \n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "num_days = 730\n",
    "start=dt.date(2021, 1, 1)\n",
    "start = max(start, dt.date.today() - dt.timedelta(days=num_days-1))\n",
    "end = dt.date.today() \n",
    "print(start, end)\n",
    "data = yf.download(\"SPY\", interval=\"1h\", start=start, end=end, prepost=True)\n",
    "data = data.drop(['Adj Close'], axis=1)\n",
    "data.index = list(map(lambda x: dt.datetime.strptime(str(x).replace(\":\",\"\"), '%Y-%m-%d %H%M%S%z').replace(tzinfo=None), data.index))\n",
    "data = data.rename_axis(\"Datetime\").reset_index()\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestr = '2022-07-28 04:00:00'\n",
    "output = dt.datetime.strptime(timestr, '%Y-%m-%d %H:%M:%S')\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bokeh.colors\n",
    "\n",
    "# for c in dir(bokeh.colors.named):\n",
    "    # print(c, c.__class__)\n",
    "import bokeh.palettes\n",
    "print(bokeh.palettes.Dark2_8)\n",
    "\n",
    "# print(bokeh.colors.named.blue.__class__)\n",
    "# print(all_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top gainers aftermath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tradingview_screener import *\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "n_rows, df = (Query()\n",
    " .select('name', 'close', 'change', 'volume', 'relative_volume_10d_calc', 'market_cap_basic', 'float_shares_outstanding')\n",
    " .where(\n",
    "     Column('market_cap_basic') >= 1_000_000,\n",
    "     Column('relative_volume_10d_calc') > 1.2,\n",
    "     Column('change') > 5,\n",
    "     Column('volume') > 1E6,\n",
    "     Column('close') > 2,\n",
    "    )\n",
    " .order_by('change', ascending=False)\n",
    " .get_scanner_data())\n",
    "\n",
    "df.volume = df.volume * 1E-6\n",
    "df.market_cap_basic = df.market_cap_basic * 1E-6\n",
    "df.float_shares_outstanding = df.float_shares_outstanding * 1E-6\n",
    "df = df.rename(columns={\n",
    "    \"volume\": \"Volume (M)\", \n",
    "    \"market_cap_basic\": \"Market Cap (M)\",\n",
    "    \"change\": \"Change %\",\n",
    "    \"float_shares_outstanding\": \"Float (M)\"\n",
    "    })\n",
    "df = df[df.ticker.str.contains(\"NASDAQ:\") | df.ticker.str.contains(\"NYSE:\")]\n",
    "print(len(df))\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from pandas.tseries.offsets import BDay\n",
    "\n",
    "(dt.date(2024, 9, 1) - BDay(0)).date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from pandas.tseries.offsets import BDay\n",
    "\n",
    "# all_data = {dt.date.today() : df.ticker.to_list()}\n",
    "fake_date_range = [dt.date(2024, 9, i) for i in range(1, 30)]\n",
    "fake_data = {fake_date_range[i//2] : [str(j) for j in range(i, i+3)] for i in range(0, len(fake_date_range)*2,2)}\n",
    "print(fake_data)\n",
    "\n",
    "\n",
    "observation_time = 1 # days after making top gainer list\n",
    "for today_date in fake_date_range:\n",
    "    stocks_to_scan = set()\n",
    "    for time_delta in range(observation_time + 1):\n",
    "        # lookback_date = (today_date - BDay(time_delta)).date()\n",
    "        lookback_date = today_date - dt.timedelta(days=time_delta)\n",
    "        print(lookback_date)\n",
    "        if lookback_date in fake_data:\n",
    "            stocks_to_scan.update(fake_data[lookback_date])\n",
    "            print(\"updated:\", fake_data[lookback_date])\n",
    "    print(today_date, stocks_to_scan)\n",
    "    print()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Premarket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tradingview_screener import *\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "n_rows, df = (\n",
    "    Scanner.premarket_gainers\n",
    "    .select('name', 'close', 'volume', 'premarket_change', 'premarket_volume', 'relative_volume_10d_calc', 'market_cap_basic', 'float_shares_outstanding')\n",
    "    .where(\n",
    "     Column('market_cap_basic') >= 1_000_000,\n",
    "     Column('relative_volume_10d_calc') > 1.2,\n",
    "     Column('premarket_change') > 5,\n",
    "     Column('premarket_volume') > 1E6,\n",
    "     Column('close') > 1\n",
    "    )\n",
    "    .get_scanner_data())\n",
    "\n",
    "\n",
    "df.volume = df.volume * 1E-6\n",
    "df.market_cap_basic = df.market_cap_basic * 1E-6\n",
    "df.premarket_volume = df.premarket_volume * 1E-6\n",
    "df.float_shares_outstanding = df.float_shares_outstanding * 1E-6\n",
    "df = df.rename(columns={\n",
    "    \"volume\": \"Volume (M)\", \n",
    "    \"market_cap_basic\": \"Market Cap (M)\",\n",
    "    \"premarket_change\": \"Premarket %\",\n",
    "    \"premarket_change_abs\": \"Premarket $\",\n",
    "    \"premarket_volume\": \"Premarket Volume (M)\",\n",
    "    \"float_shares_outstanding\": \"Float (M)\"\n",
    "    })\n",
    "print(n_rows)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from download import *\n",
    "from visualize import *\n",
    "\n",
    "yf_df = download_from_yf(\"EBS\", \"1m\", dt.date(2024,8,28), dt.date(2024,8,30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', 2500)\n",
    "display(yf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from download import *\n",
    "from visualize import *\n",
    "\n",
    "polygon_df = download_from_polygon(\"EBS\", \"4h\", dt.date(2024,8,28), dt.date(2024,8,30))\n",
    "display(polygon_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 3000)\n",
    "merged_df = yf_df.merge(polygon_df, how='left')\n",
    "display(merged_df)\n",
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_open = pd.to_datetime('09:30:00').time()\n",
    "market_close = pd.to_datetime('16:00:00').time()\n",
    "\n",
    "pre_post_data = polygon_df.loc[(polygon_df['Datetime'].dt.time <= market_open) | (polygon_df['Datetime'].dt.time >= market_close)]\n",
    "\n",
    "# TODO: Lookup not by exact value, but by the closest timestamp in yf_df after the query timestamp. \n",
    "for index, row in pre_post_data.iterrows():\n",
    "    yf_row = yf_df[yf_df['Datetime'] == row.Datetime]\n",
    "    assert len(yf_row) <= 1, \"Multiple of the same timestamps found.\"\n",
    "    yf_df.loc[yf_row.index, 'Volume'] = row.Volume\n",
    "    \n",
    "\n",
    "# pre_post_data[\"closest_timestamp\"] = pd.merge_asof(pre_post_data, yf_df, on='Datetime', direction='forward')['Datetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_market_calendars as mcal\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "market_schedule = mcal.get_calendar('NYSE').schedule(start_date='2024-01-01', end_date='2024-12-31')\n",
    "regular_business_days = market_schedule.loc[market_schedule['market_close'].dt.time >= pd.to_datetime('20:00:00').time()].index.to_list()\n",
    "\n",
    "regular_business_days = [i.to_pydatetime().date() for i in regular_business_days]\n",
    "print(regular_business_days)\n",
    "print((dt.datetime.now().date() + dt.timedelta(days=1)) in regular_business_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import datetime as dt\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "interval = 'Daily' # '5min'\n",
    "# url = f\"https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY&symbol=IBM&interval={interval}&outputsize=full&apikey=demo\"\n",
    "url = f\"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol=IBM&outputsize=full&apikey=demo\"\n",
    "r = requests.get(url)\n",
    "data = r.json()\n",
    "\n",
    "# data = yf.download('IBM', interval='1d', start=dt.datetime(1914,1,1), end=dt.datetime.today(), prepost=True, progress=False)\n",
    "# display(data)\n",
    "\n",
    "df = pd.DataFrame(columns=[\"Datetime\", 'Open', 'High', 'Low', 'Close', 'Volume'])\n",
    "for timestamp, ohlcv in data[f\"Time Series ({interval})\"].items():\n",
    "    df = pd.concat([pd.DataFrame([[dt.datetime.fromisoformat(timestamp),\n",
    "                     ohlcv['1. open'],\n",
    "                     ohlcv['2. high'],\n",
    "                     ohlcv['3. low'],\n",
    "                     ohlcv['4. close'],\n",
    "                     ohlcv['5. volume']]], columns=df.columns), df], ignore_index=True)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from download import * \n",
    "\n",
    "df = download_and_save(\"EBS\", \"1m\", save_to_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 2500)\n",
    "display(df)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bisect import bisect_left\n",
    "import datetime as dt\n",
    "from download import * \n",
    "for query_date in [dt.date(2024, 1, 1) + dt.timedelta(days=i) for i in range(365)]:\n",
    "    result = most_recent_business_day(query_date)\n",
    "    print(query_date, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "References: \n",
    "https://www.projectpro.io/recipes/upload-files-to-google-drive-using-python\n",
    "https://stackoverflow.com/questions/75454425/access-blocked-project-has-not-completed-the-google-verification-process\n",
    "https://pythonhosted.org/PyDrive/oauth.html\n",
    "'''\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "\n",
    "file = 'C:\\\\Users\\\\georg\\\\GitHub\\\\money-tree\\\\test_run.html'\n",
    "\n",
    "gauth = GoogleAuth(settings_file='C:\\\\Users\\\\georg\\\\GitHub\\\\money-tree\\\\settings.yaml', http_timeout=30)\n",
    "drive = GoogleDrive(gauth)\n",
    "upload_file_list = [file] \n",
    "for upload_file in upload_file_list: \n",
    "    gfile = drive.CreateFile({'parents': [{'id': '1N_7YUWKB2ezW_d_fse719Xo_toFuqx0q'}]}) # Read file and set it as the content of this instance. \n",
    "    gfile.SetContentFile(upload_file) \n",
    "    gfile.Upload() # Upload the file.\n",
    "\n",
    "# list file\n",
    "file_list = drive.ListFile({'q': \"'{}' in parents and trashed=false\".format('1N_7YUWKB2ezW_d_fse719Xo_toFuqx0q')}).GetList() \n",
    "for file in file_list: \n",
    "    print('title: %s, id: %s' % (file['title'], file['id']))\n",
    "\n",
    "# # download file\n",
    "# for i, file in enumerate(sorted(file_list, key = lambda x: x['title']), start=1):\n",
    "#     print('Downloading {} file from GDrive ({}/{})'.format(file['title'], i, len(file_list))) \n",
    "#     file.GetContentFile(file['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.platform)\n",
    "import platform\n",
    "print(platform.system())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from download import * \n",
    "import os\n",
    "test_pickle_path = pickle_filepath(\"NVDA\", \"1d\")\n",
    "print(test_pickle_path)\n",
    "print(os.path.exists(test_pickle_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import datetime as dt\n",
    "from download import * \n",
    "\n",
    "# data = download_from_polygon(\"NVDA\", \"1h\", start=dt.date(2024, 9, 10), end = dt.date(2024, 9, 10))\n",
    "# display(data)\n",
    "\n",
    "data = download_from_yf(\"USDJPY=X\", \"1h\", start=dt.date(2024, 9, 10), end = dt.date(2024, 9, 10))\n",
    "display(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from download import * \n",
    "data = download_and_save(\"NVDA\", \"1h\")\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "filepath = \"G:\\\\My Drive\\\\data\\\\QH_1h.pkl\"\n",
    "print(os.path.exists(filepath))\n",
    "with open(filepath, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "pd.set_option('display.max_rows', 2500)\n",
    "display(data)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from download import *\n",
    "\n",
    "is_strictly_continuous(data['Datetime'], '4h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['CHSN']: YFPricesMissingError('$%ticker%: possibly delisted; No price data found  (1m 2024-10-08 -> 2024-10-09)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$CHSN: possibly delisted; No price data found  (1m 2024-10-08 -> 2024-10-09)\n",
      "WARNING: Empty YF query!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Datetime, Open, High, Low, Close, Volume]\n",
       "Index: []"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from download import * \n",
    "(download_from_yf(\"CHSN\", \"1m\", dt.date(2024,10,8), dt.date(2024,10,8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Business days loaded!\n",
      "Downloading:\tNVDA\t1h\t2024-10-17\t2024-10-17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-10-17 04:00:00</td>\n",
       "      <td>138.430000</td>\n",
       "      <td>139.400000</td>\n",
       "      <td>137.300000</td>\n",
       "      <td>139.120000</td>\n",
       "      <td>1448593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-10-17 05:00:00</td>\n",
       "      <td>139.130000</td>\n",
       "      <td>139.320000</td>\n",
       "      <td>138.830000</td>\n",
       "      <td>138.850000</td>\n",
       "      <td>679409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-10-17 06:00:00</td>\n",
       "      <td>138.900000</td>\n",
       "      <td>139.330000</td>\n",
       "      <td>138.600000</td>\n",
       "      <td>139.300000</td>\n",
       "      <td>1512980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-10-17 07:00:00</td>\n",
       "      <td>139.300000</td>\n",
       "      <td>140.300000</td>\n",
       "      <td>139.200000</td>\n",
       "      <td>139.859000</td>\n",
       "      <td>2358342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-10-17 08:00:00</td>\n",
       "      <td>139.840000</td>\n",
       "      <td>140.230000</td>\n",
       "      <td>135.410000</td>\n",
       "      <td>139.770000</td>\n",
       "      <td>5982131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-10-17 09:00:00</td>\n",
       "      <td>139.790000</td>\n",
       "      <td>140.300000</td>\n",
       "      <td>132.785000</td>\n",
       "      <td>139.330000</td>\n",
       "      <td>72170977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-10-17 09:30:00</td>\n",
       "      <td>139.350006</td>\n",
       "      <td>140.889999</td>\n",
       "      <td>137.375000</td>\n",
       "      <td>139.600601</td>\n",
       "      <td>121786439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024-10-17 10:30:00</td>\n",
       "      <td>139.604996</td>\n",
       "      <td>139.740005</td>\n",
       "      <td>138.389999</td>\n",
       "      <td>139.649994</td>\n",
       "      <td>40698586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024-10-17 11:30:00</td>\n",
       "      <td>139.649994</td>\n",
       "      <td>140.251999</td>\n",
       "      <td>139.220001</td>\n",
       "      <td>139.460098</td>\n",
       "      <td>32335890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2024-10-17 12:30:00</td>\n",
       "      <td>139.464996</td>\n",
       "      <td>139.679993</td>\n",
       "      <td>138.893402</td>\n",
       "      <td>139.539902</td>\n",
       "      <td>21696482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2024-10-17 13:30:00</td>\n",
       "      <td>139.535004</td>\n",
       "      <td>139.919998</td>\n",
       "      <td>138.309998</td>\n",
       "      <td>138.664001</td>\n",
       "      <td>23245295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2024-10-17 14:30:00</td>\n",
       "      <td>138.664993</td>\n",
       "      <td>138.979996</td>\n",
       "      <td>137.910004</td>\n",
       "      <td>137.926193</td>\n",
       "      <td>23161284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2024-10-17 15:30:00</td>\n",
       "      <td>137.949997</td>\n",
       "      <td>138.169998</td>\n",
       "      <td>136.869995</td>\n",
       "      <td>136.919998</td>\n",
       "      <td>23689363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2024-10-17 16:00:00</td>\n",
       "      <td>136.920000</td>\n",
       "      <td>137.680000</td>\n",
       "      <td>136.330000</td>\n",
       "      <td>137.290000</td>\n",
       "      <td>4431588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2024-10-17 17:00:00</td>\n",
       "      <td>137.288000</td>\n",
       "      <td>146.838700</td>\n",
       "      <td>135.829800</td>\n",
       "      <td>137.390000</td>\n",
       "      <td>580022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2024-10-17 18:00:00</td>\n",
       "      <td>137.395000</td>\n",
       "      <td>137.700000</td>\n",
       "      <td>136.930000</td>\n",
       "      <td>137.570000</td>\n",
       "      <td>472032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2024-10-17 19:00:00</td>\n",
       "      <td>137.530000</td>\n",
       "      <td>137.550000</td>\n",
       "      <td>137.280000</td>\n",
       "      <td>137.390000</td>\n",
       "      <td>490280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Datetime        Open        High         Low       Close  \\\n",
       "0  2024-10-17 04:00:00  138.430000  139.400000  137.300000  139.120000   \n",
       "1  2024-10-17 05:00:00  139.130000  139.320000  138.830000  138.850000   \n",
       "2  2024-10-17 06:00:00  138.900000  139.330000  138.600000  139.300000   \n",
       "3  2024-10-17 07:00:00  139.300000  140.300000  139.200000  139.859000   \n",
       "4  2024-10-17 08:00:00  139.840000  140.230000  135.410000  139.770000   \n",
       "5  2024-10-17 09:00:00  139.790000  140.300000  132.785000  139.330000   \n",
       "6  2024-10-17 09:30:00  139.350006  140.889999  137.375000  139.600601   \n",
       "7  2024-10-17 10:30:00  139.604996  139.740005  138.389999  139.649994   \n",
       "8  2024-10-17 11:30:00  139.649994  140.251999  139.220001  139.460098   \n",
       "9  2024-10-17 12:30:00  139.464996  139.679993  138.893402  139.539902   \n",
       "10 2024-10-17 13:30:00  139.535004  139.919998  138.309998  138.664001   \n",
       "11 2024-10-17 14:30:00  138.664993  138.979996  137.910004  137.926193   \n",
       "12 2024-10-17 15:30:00  137.949997  138.169998  136.869995  136.919998   \n",
       "13 2024-10-17 16:00:00  136.920000  137.680000  136.330000  137.290000   \n",
       "14 2024-10-17 17:00:00  137.288000  146.838700  135.829800  137.390000   \n",
       "15 2024-10-17 18:00:00  137.395000  137.700000  136.930000  137.570000   \n",
       "16 2024-10-17 19:00:00  137.530000  137.550000  137.280000  137.390000   \n",
       "\n",
       "       Volume  \n",
       "0     1448593  \n",
       "1      679409  \n",
       "2     1512980  \n",
       "3     2358342  \n",
       "4     5982131  \n",
       "5    72170977  \n",
       "6   121786439  \n",
       "7    40698586  \n",
       "8    32335890  \n",
       "9    21696482  \n",
       "10   23245295  \n",
       "11   23161284  \n",
       "12   23689363  \n",
       "13    4431588  \n",
       "14     580022  \n",
       "15     472032  \n",
       "16     490280  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from download import * \n",
    "import datetime as dt\n",
    "data = download_and_save(\"NVDA\", \"1h\", dt.date(2024,10,17), dt.date(2024,10,17), save_to_pickle=False)\n",
    "display(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading:\tBBLG\t1m\t2024-10-18\t2024-10-18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.91</td>\n",
       "      <td>1.91</td>\n",
       "      <td>1.91</td>\n",
       "      <td>1.91</td>\n",
       "      <td>2024-10-18 04:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>640</td>\n",
       "      <td>1.94</td>\n",
       "      <td>1.94</td>\n",
       "      <td>1.94</td>\n",
       "      <td>1.93</td>\n",
       "      <td>2024-10-18 05:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2024-10-18 05:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>1.94</td>\n",
       "      <td>1.94</td>\n",
       "      <td>1.94</td>\n",
       "      <td>1.94</td>\n",
       "      <td>2024-10-18 05:21:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>1.94</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.94</td>\n",
       "      <td>2024-10-18 05:22:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>500</td>\n",
       "      <td>2.09</td>\n",
       "      <td>2.09</td>\n",
       "      <td>2.09</td>\n",
       "      <td>2.09</td>\n",
       "      <td>2024-10-18 19:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>4890</td>\n",
       "      <td>2.13</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2.13</td>\n",
       "      <td>2024-10-18 19:44:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>400</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2024-10-18 19:49:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>0</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2024-10-18 19:51:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>231</td>\n",
       "      <td>2.06</td>\n",
       "      <td>2.06</td>\n",
       "      <td>2.06</td>\n",
       "      <td>2.06</td>\n",
       "      <td>2024-10-18 19:54:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Volume  Open  Close  High   Low            Datetime\n",
       "0         0  1.91   1.91  1.91  1.91 2024-10-18 04:20:00\n",
       "0       640  1.94   1.94  1.94  1.93 2024-10-18 05:00:00\n",
       "1      1000  1.95   1.95  1.95  1.95 2024-10-18 05:20:00\n",
       "2       100  1.94   1.94  1.94  1.94 2024-10-18 05:21:00\n",
       "3      1000  1.94   1.95  1.95  1.94 2024-10-18 05:22:00\n",
       "..      ...   ...    ...   ...   ...                 ...\n",
       "515     500  2.09   2.09  2.09  2.09 2024-10-18 19:40:00\n",
       "516    4890  2.13   2.16  2.16  2.13 2024-10-18 19:44:00\n",
       "517     400  2.16   2.16  2.16  2.16 2024-10-18 19:49:00\n",
       "506       0  2.10   2.10  2.10  2.10 2024-10-18 19:51:33\n",
       "518     231  2.06   2.06  2.06  2.06 2024-10-18 19:54:00\n",
       "\n",
       "[569 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-10-17 04:00:00</td>\n",
       "      <td>138.43</td>\n",
       "      <td>139.40</td>\n",
       "      <td>137.30</td>\n",
       "      <td>139.120</td>\n",
       "      <td>1448593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-10-17 05:00:00</td>\n",
       "      <td>139.13</td>\n",
       "      <td>139.32</td>\n",
       "      <td>138.83</td>\n",
       "      <td>138.850</td>\n",
       "      <td>679409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-10-17 06:00:00</td>\n",
       "      <td>138.90</td>\n",
       "      <td>139.33</td>\n",
       "      <td>138.60</td>\n",
       "      <td>139.300</td>\n",
       "      <td>1512980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-10-17 07:00:00</td>\n",
       "      <td>139.30</td>\n",
       "      <td>140.30</td>\n",
       "      <td>139.20</td>\n",
       "      <td>139.859</td>\n",
       "      <td>2358342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-10-17 08:00:00</td>\n",
       "      <td>139.84</td>\n",
       "      <td>140.23</td>\n",
       "      <td>135.41</td>\n",
       "      <td>139.770</td>\n",
       "      <td>5982131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>2024-10-18 19:40:00</td>\n",
       "      <td>2.09</td>\n",
       "      <td>2.09</td>\n",
       "      <td>2.09</td>\n",
       "      <td>2.090</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>2024-10-18 19:44:00</td>\n",
       "      <td>2.13</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2.13</td>\n",
       "      <td>2.160</td>\n",
       "      <td>4890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>2024-10-18 19:49:00</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2.160</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>2024-10-18 19:51:33</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>2024-10-18 19:54:00</td>\n",
       "      <td>2.06</td>\n",
       "      <td>2.06</td>\n",
       "      <td>2.06</td>\n",
       "      <td>2.060</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>586 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Datetime    Open    High     Low    Close   Volume\n",
       "0   2024-10-17 04:00:00  138.43  139.40  137.30  139.120  1448593\n",
       "1   2024-10-17 05:00:00  139.13  139.32  138.83  138.850   679409\n",
       "2   2024-10-17 06:00:00  138.90  139.33  138.60  139.300  1512980\n",
       "3   2024-10-17 07:00:00  139.30  140.30  139.20  139.859  2358342\n",
       "4   2024-10-17 08:00:00  139.84  140.23  135.41  139.770  5982131\n",
       "..                  ...     ...     ...     ...      ...      ...\n",
       "581 2024-10-18 19:40:00    2.09    2.09    2.09    2.090      500\n",
       "582 2024-10-18 19:44:00    2.13    2.16    2.13    2.160     4890\n",
       "583 2024-10-18 19:49:00    2.16    2.16    2.16    2.160      400\n",
       "584 2024-10-18 19:51:33    2.10    2.10    2.10    2.100        0\n",
       "585 2024-10-18 19:54:00    2.06    2.06    2.06    2.060      231\n",
       "\n",
       "[586 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "empty_df = download_and_save(\"BBLG\", interval=\"1m\", start=dt.date.today(), end=dt.date.today())\n",
    "display(empty_df)\n",
    "data = data.merge(empty_df, how='outer')\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one time fix data\n",
    "from download import *\n",
    "# affected_tickers = ['SOBR', 'HEPS', 'DRUG', 'JDZG', 'PEGY', 'AKAN', 'TNON', 'TVGN', 'SLRX', 'MGRX', \"PRME\", \"GFI\", \"RTO\"]\n",
    "# for ticker in affected_tickers:\n",
    "#     os.remove(pickle_filepath(ticker, \"1h\"))\n",
    "\n",
    "# # add it back\n",
    "# for ticker in affected_tickers:\n",
    "#     download_and_save(ticker, \"1h\", dt.date(2024,10,18), dt.date(2024,10,18), save_to_pickle=True)\n",
    "\n",
    "# affected_tickers = [\"QQQ\", \"SPY\", \"VOO\", \"NVDA\", \"MSFT\"]\n",
    "# for ticker in affected_tickers:\n",
    "#     os.remove(pickle_filepath(ticker, \"1h\"))\n",
    "\n",
    "# # add it back\n",
    "# for ticker in affected_tickers:\n",
    "#     download_and_save(ticker, \"1h\", save_to_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from download import *\n",
    "test_ticker = \"BBLG\"\n",
    "test_interval = \"5m\"\n",
    "df = download_and_save(test_ticker, interval=test_interval, start=dt.date(2024,10,13), end=dt.date(2024,10,14), save_to_pickle=False)\n",
    "pd.set_option('display.max_rows', 2500)\n",
    "display(df)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "is_df_continuous, missing_times = is_strictly_continuous(df['Datetime'], test_interval)\n",
    "print(is_df_continuous, missing_times)\n",
    "is_df_continuous, missing_times = is_loosely_continuous(df['Datetime'], test_interval)\n",
    "print(is_df_continuous, missing_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from download import *\n",
    "big_names = {\"QQQ\", \"SPY\", \"VOO\", \"NVDA\", \"MSFT\"}\n",
    "affected_tickers = set()\n",
    "folder = os.path.join(BASE_DIR, \"data\")\n",
    "for f in os.listdir(folder):\n",
    "    if \"_1h.pkl\" in f:\n",
    "        affected_tickers.add(f.removesuffix(\"_1h.pkl\"))\n",
    "\n",
    "affected_tickers.difference_update(big_names)\n",
    "repair_1h_info = dict()\n",
    "to_delete = []\n",
    "for ticker in affected_tickers:\n",
    "    df = get_downloaded_data_or_none(ticker, \"1h\")\n",
    "    if df is None or dt.time(hour=10, minute=0) in df['Datetime'].dt.time.unique(): \n",
    "        to_delete.append(ticker)\n",
    "    else:\n",
    "        repair_1h_info[ticker] = df['Datetime'].dt.date.unique()\n",
    "print(repair_1h_info.keys())\n",
    "\n",
    "# print(to_delete)\n",
    "# for ticker in to_delete:\n",
    "#     os.remove(pickle_filepath(ticker, \"1h\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ticker, dates in repair_1h_info.items():\n",
    "#     os.remove(pickle_filepath(ticker, \"1h\"))\n",
    "#     for date in dates:\n",
    "#         download_and_save(ticker, \"1h\", date, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-22\n",
      "{'ticker': 'NVDA', 'queryCount': 1916, 'resultsCount': 32, 'adjusted': True, 'results': [{'v': 1448593.0, 'vw': 139.0433, 'o': 138.2, 'c': 139.18, 'h': 139.4, 'l': 137.05, 't': 1729152000000, 'n': 18142}, {'v': 679409, 'vw': 138.9565, 'o': 139.18, 'c': 138.9, 'h': 139.32, 'l': 138.6, 't': 1729155600000, 'n': 7880}, {'v': 1512980.0, 'vw': 139.6743, 'o': 138.9, 'c': 140.08, 'h': 140.3, 'l': 138.9, 't': 1729159200000, 'n': 17847}, {'v': 2358342.0, 'vw': 139.8543, 'o': 140.07, 'c': 139.95, 'h': 140.09, 'l': 139.56, 't': 1729162800000, 'n': 20823}, {'v': 5982131.0, 'vw': 139.5221, 'o': 139.94, 'c': 139.94, 'h': 140.065, 'l': 135.41, 't': 1729166400000, 'n': 45219}, {'v': 72170977.0, 'vw': 139.4627, 'o': 139.94, 'c': 138.865, 'h': 140.89, 'l': 137.65, 't': 1729170000000, 'n': 470845}, {'v': 62630410.0, 'vw': 138.8939, 'o': 138.88, 'c': 139.12, 'h': 139.75, 'l': 137.3648, 't': 1729173600000, 'n': 423853}, {'v': 32071604.0, 'vw': 139.54, 'o': 139.13, 'c': 140.104, 'h': 140.13, 'l': 138.6, 't': 1729177200000, 'n': 274426}, {'v': 26645755.0, 'vw': 139.6112, 'o': 140.11, 'c': 139, 'h': 140.252, 'l': 138.893362, 't': 1729180800000, 'n': 171740}, {'v': 16714879.0, 'vw': 139.5378, 'o': 139, 'c': 139.51, 'h': 139.92, 'l': 138.9, 't': 1729184400000, 'n': 112503}, {'v': 26644727.0, 'vw': 138.7615, 'o': 139.51, 'c': 138.9199, 'h': 139.58, 'l': 138.11, 't': 1729188000000, 'n': 165429}, {'v': 35288853.0, 'vw': 137.7749, 'o': 138.914, 'c': 136.92, 'h': 139.32, 'l': 136.87, 't': 1729191600000, 'n': 233346}, {'v': 4431588.0, 'vw': 137.0213, 'o': 136.92, 'c': 137.26, 'h': 137.68, 'l': 136.34, 't': 1729195200000, 'n': 15962}, {'v': 580022, 'vw': 137.3786, 'o': 137.288, 'c': 137.39, 'h': 137.49, 'l': 137.22, 't': 1729198800000, 'n': 5475}, {'v': 472032, 'vw': 137.5471, 'o': 137.4, 'c': 137.54, 'h': 137.7, 'l': 137.34, 't': 1729202400000, 'n': 4365}, {'v': 490280, 'vw': 137.3882, 'o': 137.5285, 'c': 137.39, 'h': 137.5496, 'l': 137.28, 't': 1729206000000, 'n': 4456}, {'v': 562318, 'vw': 138.4192, 'o': 138.5, 'c': 138.46, 'h': 138.83, 'l': 137.79, 't': 1729238400000, 'n': 7548}, {'v': 244849, 'vw': 138.4333, 'o': 138.49, 'c': 138.2, 'h': 138.64, 'l': 138.04, 't': 1729242000000, 'n': 3410}, {'v': 250134, 'vw': 138.28, 'o': 138.25, 'c': 138.19, 'h': 138.45, 'l': 138.06, 't': 1729245600000, 'n': 3468}, {'v': 1148706.0, 'vw': 138.2381, 'o': 138.17, 'c': 138.2, 'h': 138.5, 'l': 137.74, 't': 1729249200000, 'n': 8853}, {'v': 2583007.0, 'vw': 138.3789, 'o': 138.14, 'c': 138.68, 'h': 138.78, 'l': 137.22, 't': 1729252800000, 'n': 19933}, {'v': 38417436.0, 'vw': 138.3131, 'o': 138.7, 'c': 137.99, 'h': 139.15, 'l': 137.38, 't': 1729256400000, 'n': 216923}, {'v': 28215599.0, 'vw': 138.0445, 'o': 137.98, 'c': 137.534, 'h': 138.5, 'l': 137.45, 't': 1729260000000, 'n': 215327}, {'v': 16455724.0, 'vw': 137.8528, 'o': 137.5399, 'c': 137.8647, 'h': 138.1, 'l': 137.48, 't': 1729263600000, 'n': 176446}, {'v': 18177656.0, 'vw': 137.8053, 'o': 137.87, 'c': 138.24, 'h': 138.42, 'l': 137.28, 't': 1729267200000, 'n': 113427}, {'v': 16483892.0, 'vw': 138.3714, 'o': 138.2301, 'c': 138.29, 'h': 138.67, 'l': 138.15, 't': 1729270800000, 'n': 100714}, {'v': 12970546.0, 'vw': 138.1984, 'o': 138.295, 'c': 138.035, 'h': 138.405, 'l': 137.9201, 't': 1729274400000, 'n': 78844}, {'v': 19324944.0, 'vw': 138.0398, 'o': 138.03, 'c': 137.98, 'h': 138.25, 'l': 137.87, 't': 1729278000000, 'n': 122987}, {'v': 7075474.0, 'vw': 137.9994, 'o': 138, 'c': 138.01, 'h': 138.04, 'l': 137.93, 't': 1729281600000, 'n': 5484}, {'v': 275301, 'vw': 135.4513, 'o': 138.01, 'c': 138, 'h': 138.03, 'l': 137.98, 't': 1729285200000, 'n': 2819}, {'v': 143566, 'vw': 137.9947, 'o': 137.99, 'c': 137.97, 'h': 138.02, 'l': 137.95, 't': 1729288800000, 'n': 2115}, {'v': 251661, 'vw': 137.9693, 'o': 137.96, 'c': 138, 'h': 138, 'l': 137.9102, 't': 1729292400000, 'n': 3018}], 'status': 'OK', 'request_id': '6526bc68ec636a6ec87fc773601e34b5', 'count': 32}\n",
      "2022-10-24 08:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\georg\\AppData\\Local\\Temp\\ipykernel_32148\\2650934983.py:15: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  print(dt.datetime.utcfromtimestamp(1666598400).strftime('%Y-%m-%d %H:%M:%S'))\n"
     ]
    }
   ],
   "source": [
    "from download import *\n",
    "# print(dt.date.today()- dt.timedelta(days=60))\n",
    "# data = yf.download(\"NVDA\", interval=\"5m\", start=dt.date(2024, 8, 23), end=dt.date.today(), prepost=True)\n",
    "# print(sorted(list(set(data.index.date))))\n",
    "\n",
    "print(dt.date.today()- dt.timedelta(days=730))\n",
    "interval = \"1h\"\n",
    "start = dt.date(2024, 10,17)\n",
    "end = dt.date(2024, 10,18)\n",
    "interval_abbrev_dict = {\"m\": \"minute\", \"h\": \"hour\", \"d\": \"day\"}\n",
    "interval_arg = interval[:-1] + \"/\" + interval_abbrev_dict[interval[-1]]\n",
    "polygon_url = f\"https://api.polygon.io/v2/aggs/ticker/NVDA/range/{interval_arg}/{start.isoformat()}/{end.isoformat()}?adjusted=true&sort=asc&limit=50000&apiKey={os.environ['POLYGON_API_KEY']}\"\n",
    "r = requests.get(polygon_url)\n",
    "print(r.json())\n",
    "print(dt.datetime.utcfromtimestamp(1666598400).strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from download import *\n",
    "total_df = pd.DataFrame(columns=[\"Datetime\", 'Open', 'High', 'Low', 'Close', 'Volume'])  \n",
    "total_df = total_df.drop_duplicates(\"Datetime\").sort_values(by=\"Datetime\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
